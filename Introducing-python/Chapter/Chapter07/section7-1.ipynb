{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7章 プロのようにデータを操る\n",
    "---\n",
    "この章では、データを自在に操るためのさまざまなテクニックを学ぶ。その大半は次の組み込みデータ型に関係するものだ。\n",
    "\n",
    "- 文字列\n",
    "  - Unicode文字のシーケンス。テキストデータで使われる。\n",
    "- バイトとバイト列\n",
    "  - 8ビット整数のシーケンス。バイナリデータで使われる。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.1 文字列\n",
    "---\n",
    "テキスト（文字列）はほとんどの読者にとってもっとも馴染み深いデータだろう。そこで、Python文字列の強力な機能から説明を始めることにしよう。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.1.1 Unicode\n",
    "---\n",
    "本書の今までのテキスト関連のサンプルでは、すべてASCIIを使ってきた。ASCIIは、コンピュータが冷蔵庫ほどの大きさで、計算が少し得意なだけだった1960年代に定義されたものだ。コンピュータの記憶の基本単位は**バイト**で、8個の**ビット**を使って256種類の一意な値を表現出来る。さまざまな理由から、ASCIIは7ビット（128種類の一意な値）しか使っていない。26種類の大文字、26種類の小文字、10種類の数字、いくつかの記号、いくつかの空白文字、そしていくつかの表示されない制御コードが含まれている。\n",
    "\n",
    "残念ながら、世界にはASCIIで表現できる以上の文字がある。夕食にホットドッグは食べられても、カフェ（café）でGewürztraminerを飲むことはできなくなってしまう。文字と記号を増やすために、さまざまな試みがなされてきた。ときどき、それを見かけることもあるだろう。そのような試みからふたつだけを紹介しておこう。\n",
    "\n",
    "- Latin-1、あるいはISO 8859-1\n",
    "- Windowsコードページ1252\n",
    "\n",
    "これらは8ビットをフルに使っているが、それでも十分ではないことがある。特に、ヨーロッパ以外の言語が必要になったときにはそうだ。**Unicode**は、世界の言語のすべての文字と数学、その他の分野の記号を定義しようという発展途上の国際基準である。\n",
    "\n",
    "> Unicodeは、プラットフォーム、プログラム、言語にかかわらず、すべての文字に一意な番号を与える。\n",
    "> The Unicode Consortium\n",
    "\n",
    "[Unicodeのコード一覧ページ](http://unicode.org/charts/)には、現在定義されているすべてのキャラクターセットとそのイメージへのリンクが含まれている。最新バージョン（10.0）は、12万字を超える文字、記号を定義しており、それぞれに一意な名前とID番号を与えている。文字は、**面**と呼ばれる8ビットセットに分割される。最初の256面は、基本多言語面である。詳しくは、[WikipediaのUnicode面についてのページ（日本語）](http://bit.ly/2EIoHKv)、[WikipediaのUnicode面についてページ（英語）](http://bit.ly/2Flht0e)を参照していただきたい。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7.1.1.1\n",
    "---\n",
    "Python3の文字列はUnicode文字列で、バイト列ではない。Python2から3への移行で、これがもっとも大きな変更だ。Python2は、1バイト文字列とUnicode文字列を区別していた。\n",
    "\n",
    "文字のUnicode IDまたは名前を知っている場合、Python文字列でそれを使うことができる。例をいくつか示そう。\n",
    "\n",
    "- \\uの後ろに4個の16進数字を続けたものは、256の基本多言語面のどれかに含まれる文字に対応する。最初の2桁は面番号（00からFFまで）、後半の2桁はその面のなかでの文字のインデックスを表す。面00はASCIIであり、面内での文字の位置もASCIIと同じになっている。\n",
    "- 上位面の文字は、基本多言語面の文字よりも多くのビットを必要とする。Pythonのエスケープシーケンスは、\\Uの後ろに8個の16進文字を続けたものである。左端の数字は0でなければならない。\n",
    "- すべての文字について、\\N{name}を使えば、標準の**名前**を通じてひとつの文字を指定できる。名前のリストは、[Unicode文字名索引](http://unicode.org/charts/charindex.html)にまとめられている。\n",
    "\n",
    "Pythonのunicodedataモジュールには、双方向の変換関数が含まれている。\n",
    "\n",
    "- lookup()\n",
    "  - 名前（大文字と小文字を区別しない）を与えると、Unicode文字が返される。\n",
    "- name()\n",
    "  - Unicode文字を与えると、大文字の名前が返される。\n",
    "  \n",
    "次のサンプルでは、Unicode文字を引数とするテスト関数を書いている。文字から名前を引き出し、名前から文字を引き出している（最初の文字と一致するはずだ）。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unicode_test(value):\n",
    "    import unicodedata\n",
    "    name = unicodedata.name(value)\n",
    "    value2 = unicodedata.lookup(name)\n",
    "    print('value=\"%s\", name=\"%s\", value2=\"%s\"' % (value, name, value2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "いくつかの文字を試してみよう。最初はごく平凡なASCII文字だ。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "value=\"A\", name=\"LATIN CAPITAL LETTER A\", value2=\"A\"\n"
     ]
    }
   ],
   "source": [
    "unicode_test('A')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "次はASCIIの記号である。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "value=\"$\", name=\"DOLLAR SIGN\", value2=\"$\"\n"
     ]
    }
   ],
   "source": [
    "unicode_test('$')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unicodeの通貨記号を見てみよう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "value=\"¢\", name=\"CENT SIGN\", value2=\"¢\"\n"
     ]
    }
   ],
   "source": [
    "unicode_test('\\u00a2')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unicodeの別の通貨記号だ。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "value=\"€\", name=\"EURO SIGN\", value2=\"€\"\n"
     ]
    }
   ],
   "source": [
    "unicode_test('\\u20ac')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "このテストをしていて問題になりそうなことは、テキストの表示に使っているフォントだけだ。すべてのフォントがすべてのUnicode文字のイメージを持っているわけではなく、イメージのない文字に対してはそのことを表す代替記号を表示する。たとえば、次に示すのは、Unicodeの「雪だるま」記号である。dinggatフォントに含まれている記号と同じようなものだ。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "value=\"☃\", name=\"SNOWMAN\", value2=\"☃\"\n"
     ]
    }
   ],
   "source": [
    "unicode_test('\\u2603')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pythonの文字列にCaféという単語を保存したいときにはどうすればよいだろうか。ファイルやウェブサイトからコピーアンドペーストしてうまくいくように祈るのもひとつの方法だ。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'café'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "place = 'café'\n",
    "place"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "これでうまくいったのは、テキストのためにUTF-8エンコーディング（すぐあとで説明する）を使っているソースからコピーアンドペーストしたからである。\n",
    "\n",
    "最後のéの文字はどのようにして指定すればよいのだろうか。[Eの文字列検索](http://www.unicode.org/charts/charindex.html#E)を見ると、E WITH ACUTE, LATIN SMALL LETTERという名前は00E9という値を持っていることがわかる。今いじってみたname()、lookup()関数でチェックしてみよう。まず、コードから名前を調べてみる。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'LATIN SMALL LETTER E WITH ACUTE'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import unicodedata\n",
    "unicodedata.name('\\u00E9')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "次に、名前からコードを調べてみる。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"undefined character name 'E WITH ACUTE, LATIN SMALL LETTER'\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-23-9702931d144a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0municodedata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlookup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'E WITH ACUTE, LATIN SMALL LETTER'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m: \"undefined character name 'E WITH ACUTE, LATIN SMALL LETTER'\""
     ]
    }
   ],
   "source": [
    "unicodedata.lookup('E WITH ACUTE, LATIN SMALL LETTER')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Unicode文字列検索ページは、ソート、表示に適したように整形されている。実際のUnicode名（Pythonが使っているもの）に変換するには、カンマを削除し、カンマの後ろの部分を前に移動する。そこで、E WITH ACUTE, LATIN SMALL LETTERは、LATIN SMALL LETTER E WITH ACUTEになる。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'é'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unicodedata.lookup('LATIN SMALL LETTER E WITH ACUTE')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "これで、コードから名前によってcaféという文字列を指定できるようになった。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'café'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "place = 'caf\\u00e9'\n",
    "place"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'café'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "place = 'caf\\N{LATIN SMALL LETTER E WITH ACUTE}'\n",
    "place"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "上のコードでは、文字列にéを直接挿入していたが、文字を追加して文字列を組み立てていくこともできる。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ü'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "u_umlaut = '\\N{LATIN SMALL LETTER U WITH DIAERESIS}'\n",
    "u_umlaut"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now I can finally have my Gewürstraminer in a café\n"
     ]
    }
   ],
   "source": [
    "drink = 'Gew' + u_umlaut + 'rstraminer'\n",
    "print('Now I can finally have my', drink, 'in a', place)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "文字列のlen関数は、バイト数ではなく、Unicodeの**文字数**を数える。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len('$')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len('\\U0001f47b')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7.1.1.2 UTF-8によるエンコード、デコード\n",
    "---\n",
    "通常の文字列処理をしているときには、Pythonが個々のUnicode文字をどのように格納しているかについて心配する必要はない。\n",
    "\n",
    "しかし、外部の世界との間でデータをやり取りするときには、次のふたつのことが必要になる。\n",
    "\n",
    "- 文字列をバイト列に**エンコード**する手段\n",
    "- バイト列を文字列に**デコード**する手段\n",
    "\n",
    "Unicodeが64,000文字よりも少なければ、個々のUnicode文字IDを2バイトに格納できたところだが、実際にはもっと多い。3，4バイトあればすべてのIDをエンコードできるが、それではごく普通の文字列のためにメモリやディスクで必要な容量が3、4倍に増えてしまう。\n",
    "\n",
    "Ken ThompsonとRob Pikeと言えば、Unixデベロッパーにはおなじみの名前だろう。動的エンコード方式のUTF-8は、ある晩彼らがニュージャージーの食堂の一角で設計したものである。UTF-8は、個々のUnicode文字のために1バイトから4バイトを使っている。\n",
    "\n",
    "- ASCIIは1バイト\n",
    "- ほとんどのローマ字系言語には2バイト（ただしキリル文字は除く）\n",
    "- 基本多言語面のその他については3バイト\n",
    "- 一部のアジアの言語、記号を含むその他については4バイト\n",
    "\n",
    "UtF-8はPython、Linux、HTMLでは標準的なテキストエンコーディングであり、非常によく機能している。コード全体を通じてUTF-8エンコーディングを使うなら、さまざまなエンコーディングの間を行き来するよりもはるかに仕事が楽になる。\n",
    "\n",
    "> ウェブページなどの他のソースからコピーアンドペーストでPython文字列を作るときには、ソースがUTF-8形式でエンコードされていることを確かめなければならない。Latin-1やWindows 1252でエンコードされたテキストをPython文字列にコピーしている例は**非常に**よく見かける。すると、あとで無効なバイトシーケンスだとして例外を引き起こすことになる。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7.1.1.3 エンコーディング\n",
    "---\n",
    "**文字列**をエンコードして**バイト**にする。文字列のencode()関数の第1引数は、エンコーディング名だ。表7−1にまとめられているものから選べる\n",
    "\n",
    "表7−1 エンコーディング\n",
    "\n",
    "| エンコーディング名 | 意味 |\n",
    "|:----------------|:----|\n",
    "| 'ascii'         | 古き良き7ビットASCII |\n",
    "| 'utf-8'         | 8ビット可変長エンコーディング。ほとんどかならずこれを使うことになる |\n",
    "| 'latin-1'       | ISO 8859-1とも呼ばれているもの |\n",
    "| 'cp-1259'       | 一般的なWindowsエンコーディング |\n",
    "| 'unicode-escape' | Python Unicodeリテラル方式。 \\uxxxxまたは\\Uxxxxxxxx |\n",
    "\n",
    "どんなものでもUTF-8としてエンコードすることができる。snowmanという変数にUnicode文字列'\\u2603'を代入してみよう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "snowman = '\\u2603'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Python内部に格納するために何バイトかかったかにかかわらず、snowmanは、1文字のPython Unicode文字列だ。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(snowman)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "次に、このUnicode文字をバイトシーケンスにエンコードしてみよう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = snowman.encode('utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "先ほども触れたように、UTF-8は可変長エンコーディングだ。この場合、Unicodeのたったひとつの文字をエンコードするために3バイトを使っている。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b'\\xe2\\x98\\x83'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "今度は、len()がバイト数(3)を返しているが、それはdsがbytes変数（「7.2.1 バイトとバイト列」参照）だからだ。\n",
    "\n",
    "UTF-8以外のエンコーディングも使えるが、そのエンコーディングでUnicode文字列が処理出来ない場合はエラーが返される。たとえば、asciiエンコーディングを使うと、Unicode文字が有効なASCII文字になっている場合でなければエラーになる。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "ename": "UnicodeEncodeError",
     "evalue": "'ascii' codec can't encode character '\\u2603' in position 0: ordinal not in range(128)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnicodeEncodeError\u001b[0m                        Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-36-5f5dc414d940>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msnowman\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'ascii'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mUnicodeEncodeError\u001b[0m: 'ascii' codec can't encode character '\\u2603' in position 0: ordinal not in range(128)"
     ]
    }
   ],
   "source": [
    "ds = snowman.encode('ascii')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "encode関数は、エンコード例外を起こしにくくするための第2引数を持っている。デフォルト値は、今までの例のような動作をする。'strict'で、ASCII以外の文字が使われているとUnicodeEncodeErrorを起こす。しかし、ほかの値も指定できる。'ignore'を使えば、エンコードできないものを捨ててしまう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b''"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "snowman.encode('ascii', 'ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "'replace'を使えば、エンコードできない文字を?に置き換える。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b'?'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "snowman.encode('ascii', 'replace')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "'backslashreplace'を使えば、unicode-escape形式のPython Unicode文字列を生成する。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b'\\\\u2603'"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "snowman.encode('ascii', 'backslashreplace')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unicodeエスケープシーケンスの表示可能バージョンが必要なら、これを使うことになるだろう。\n",
    "\n",
    "次のコードは、ウェブページで使えるエンティティの文字列を生成する。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b'&#9731;'"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "snowman.encode('ascii', 'xmlcharrefreplace')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7.1.1.4 デコーディング\n",
    "---\n",
    "バイト列を**デコード**してUnicode文字列にする。なんらかの外部ソース（ファイル、データベース、ウェブサイト、ネットワークAPIなど）からテキストを取り出したとき、そのテキストはバイト列としてエンコードされている。難しいのは、実際にどのエンコーディングが使われているのかを知ることだ。それがわからなければ、エンコードの「逆」をやってUnicode文字列を得ることはできない。\n",
    "\n",
    "しかし、バイト列自体のなかには、どのエンコーディングが使われているかを教えてくれるものはない。ウェブサイトからのコピーアンドペーストの危険性については先ほど触れた。古き良きASCII文字が表示されるべきところに奇妙な文字が表示されているウェブサイトを見かけたことはあるだろう。\n",
    "\n",
    "では、placeという変数で、値が'café'のUnicode文字列を作ってみよう。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'café'"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "place = 'caf\\u00e9'\n",
    "place"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(place)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "これをUTF-8形式でエンコードしてplace_bytesというbytes変数に格納しよう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b'caf\\xc3\\xa9'"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "place_bytes = place.encode('utf-8')\n",
    "place_bytes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "bytes"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(place_bytes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "place_bytesが5バイトだということに注意しよう。最初の3バイトはASCIIと同じ（UTF-8の長所）で、最後の2バイトが'é'をエンコードしている。では、バイト列をUnicode文字列にデコードしてみよう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'café'"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "place2 = place_bytes.decode('utf-8')\n",
    "place2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "これがうまく動作したのは、UTF-8にエンコードし、UTF-8からデコードしたからだ。ほかのエンコーディングからのデコードを指示したらどうなるだろうか。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "ename": "UnicodeDecodeError",
     "evalue": "'ascii' codec can't decode byte 0xc3 in position 3: ordinal not in range(128)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnicodeDecodeError\u001b[0m                        Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-48-b2f66e476fde>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mplace3\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplace_bytes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'ascii'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mUnicodeDecodeError\u001b[0m: 'ascii' codec can't decode byte 0xc3 in position 3: ordinal not in range(128)"
     ]
    }
   ],
   "source": [
    "place3 = place_bytes.decode('ascii')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ASCIIデコーダは、oxc3というバイト値がASCIIでは無効なので例外を投げている。8ビットキャラクタセットのエンコーディングでは、\n",
    "128（16進80）から255（16進FF）までの間に有効な値を持つものがあるが、それはUTF-8とは異なる値だ。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cafÃ©'"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "place4 = place_bytes.decode('latin-1')\n",
    "place4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cafÃ©'"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "place5 = place_bytes.decode('windows-1252')\n",
    "place5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "これではダメである。\n",
    "\n",
    "ここから得られる教訓は、可能な限りUTF-8エンコーディングを使えということだ。UTF-8なら正しく動作し、どこでもサポートされているし、すべてのUnicode文字を表現でき、すばやくデコード、エンコードできる。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7.1.1.5 詳しく学びたい人のために\n",
    "---\n",
    "エンコード、デコードについてもっと学びたい場合は、次のリンクが役に立つだろう。\n",
    "\n",
    "- [Unicode HOWTO](https://docs.python.org/ja/3/howto/unicode.html)\n",
    "- [Pragmatic Unicode](https://nedbatchelder.com/text/unipain.html)\n",
    "- [The Absolute Minimum Every Software Developer Absolutely, Positively Must Know About Unicode and Charactor Sets \\(No Excuses!\\)](https://www.joelonsoftware.com/2003/10/08/the-absolute-minimum-every-software-developer-absolutely-positively-must-know-about-unicode-and-character-sets-no-excuses/)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
